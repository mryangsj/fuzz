{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GlobalNorm1d(torch.nn.Module):\n",
    "    def __init__(self, input_features, eps=None, affine=True):\n",
    "        super(GlobalNorm1d, self).__init__()\n",
    "        \n",
    "        if eps is None:\n",
    "            eps = torch.finfo(torch.float32).eps\n",
    "        self.register_buffer('eps', torch.tensor(eps, dtype=torch.float32))\n",
    "        \n",
    "        self.register_buffer('count', torch.tensor(0., dtype=torch.float32))\n",
    "        self.register_buffer('mean', torch.zeros(input_features, dtype=torch.float32))\n",
    "        self.register_buffer('var', torch.ones(input_features, dtype=torch.float32))\n",
    "        \n",
    "        self.affine = affine\n",
    "        self.weight = torch.nn.Parameter(torch.ones(input_features, dtype=torch.float32)) if affine else None \n",
    "        self.bias = torch.nn.Parameter(torch.zeros(input_features, dtype=torch.float32)) if affine else None\n",
    "    \n",
    "    def update_statistics(self, x):\n",
    "        with torch.no_grad():\n",
    "            batch_mean = x.mean(dim=0).to(self.mean.device)\n",
    "            batch_count = x.size(0)\n",
    "            total_count = self.count + batch_count\n",
    "            # Update mean\n",
    "            delta = batch_mean - self.mean\n",
    "            self.mean += delta * batch_count / total_count\n",
    "            # Update variance\n",
    "            ratio = (self.count - 1) / (total_count - 1)\n",
    "            batch_var = (x - batch_mean).pow(2).sum(dim=0)\n",
    "            weighted_delta_square = delta.pow(2) * self.count * batch_count / total_count\n",
    "            self.var *= ratio\n",
    "            self.var += (batch_var + weighted_delta_square) / (total_count - 1)\n",
    "            # Update count\n",
    "            self.count = total_count\n",
    "            \n",
    "    def forward(self, x):\n",
    "        self.update_statistics(x) if self.training else None\n",
    "        normalized_x = (x - self.mean) / (self.var + self.eps).sqrt()\n",
    "        return normalized_x * self.weight + self.bias if self.affine else normalized_x\n",
    " \n",
    "\n",
    "class TwoPort(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(TwoPort, self).__init__()\n",
    "        self.gn1 = GlobalNorm1d(5)\n",
    "        self.linear1 = torch.nn.Linear(5, 16)\n",
    "        self.linear2 = torch.nn.Linear(16, 16)\n",
    "        self.linear3 = torch.nn.Linear(16, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.gn1(x)\n",
    "\n",
    "        x1 = self.linear1(x)\n",
    "        x1 = torch.nn.functional.relu(x1)\n",
    "\n",
    "        x2 = self.linear2(x1) + x1\n",
    "        x2 = torch.nn.functional.relu(x2)\n",
    "\n",
    "        x3 = self.linear3(x2)\n",
    "        return x3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gn1.eps 1.1920929e-07\n",
      "gn1.count 268435460.0\n",
      "gn1.mean [ 1.5251255e-05  4.5039244e+00  1.4293042e+04 -1.4291543e+04\n",
      "  2.8557406e+04]\n",
      "gn1.var [6.4009476e+01 1.6386786e+01 3.2561897e+01 3.2193089e+01 1.0485760e+06]\n",
      "tensor([6.4009e+01, 1.6387e+01, 3.2562e+01, 3.2193e+01, 1.0486e+06])\n"
     ]
    }
   ],
   "source": [
    "# model = torch.load('../models/2X16.pth')\n",
    "model = torch.load('../models/2X16.pth')\n",
    "\n",
    "\n",
    "# 创建或打开HDF5文件，并保存参数和缓冲区\n",
    "with h5py.File('../models/2X16.h5', 'w') as h5_file:\n",
    "    # 保存模型参数\n",
    "    for name, param in model.named_parameters():\n",
    "        layer_name, param_type = name.split('.')\n",
    "        grp = h5_file.require_group(layer_name)\n",
    "        grp.create_dataset(param_type, data=param.cpu().detach().numpy())\n",
    "\n",
    "    # 保存模型缓冲区\n",
    "    for name, buf in model.named_buffers():\n",
    "        layer_name, buf_type = name.split('.')\n",
    "        grp = h5_file.require_group(layer_name)\n",
    "        grp.create_dataset(buf_type, data=buf.cpu().numpy())\n",
    "        # print(name, buf.cpu().numpy())\n",
    "\n",
    "# print(model.gn1.var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[37], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m      8\u001b[0m     model\u001b[38;5;241m.\u001b[39meval()\n\u001b[0;32m----> 9\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch_in\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m h5py\u001b[38;5;241m.\u001b[39mFile(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../models/2x16_test.h5\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[1;32m     12\u001b[0m     file\u001b[38;5;241m.\u001b[39mcreate_dataset(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mx\u001b[39m\u001b[38;5;124m'\u001b[39m, data\u001b[38;5;241m=\u001b[39mx)\n",
      "Cell \u001b[0;32mIn[3], line 58\u001b[0m, in \u001b[0;36mTwoPort.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     55\u001b[0m x2 \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mfunctional\u001b[38;5;241m.\u001b[39mrelu(x2)\n\u001b[1;32m     57\u001b[0m x3 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlinear3(x2)\n\u001b[0;32m---> 58\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mx3\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/wdf/lib/python3.12/site-packages/debugpy/_vendored/pydevd/_pydevd_bundle/pydevd_frame.py:1197\u001b[0m, in \u001b[0;36mPyDBFrame.trace_dispatch\u001b[0;34m(self, frame, event, arg)\u001b[0m\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_line:\n\u001b[1;32m   1196\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_suspend(thread, step_cmd, original_step_cmd\u001b[38;5;241m=\u001b[39minfo\u001b[38;5;241m.\u001b[39mpydev_original_step_cmd)\n\u001b[0;32m-> 1197\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdo_wait_suspend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mthread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1198\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_return:  \u001b[38;5;66;03m# return event\u001b[39;00m\n\u001b[1;32m   1199\u001b[0m     back \u001b[38;5;241m=\u001b[39m frame\u001b[38;5;241m.\u001b[39mf_back\n",
      "File \u001b[0;32m~/miniconda3/envs/wdf/lib/python3.12/site-packages/debugpy/_vendored/pydevd/_pydevd_bundle/pydevd_frame.py:165\u001b[0m, in \u001b[0;36mPyDBFrame.do_wait_suspend\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdo_wait_suspend\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 165\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_args\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdo_wait_suspend\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/wdf/lib/python3.12/site-packages/debugpy/_vendored/pydevd/pydevd.py:2070\u001b[0m, in \u001b[0;36mPyDB.do_wait_suspend\u001b[0;34m(self, thread, frame, event, arg, exception_type)\u001b[0m\n\u001b[1;32m   2067\u001b[0m             from_this_thread\u001b[38;5;241m.\u001b[39mappend(frame_custom_thread_id)\n\u001b[1;32m   2069\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_threads_suspended_single_notification\u001b[38;5;241m.\u001b[39mnotify_thread_suspended(thread_id, thread, stop_reason):\n\u001b[0;32m-> 2070\u001b[0m         keep_suspended \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_wait_suspend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mthread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msuspend_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrom_this_thread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframes_tracker\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2072\u001b[0m frames_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   2074\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m keep_suspended:\n\u001b[1;32m   2075\u001b[0m     \u001b[38;5;66;03m# This means that we should pause again after a set next statement.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/wdf/lib/python3.12/site-packages/debugpy/_vendored/pydevd/pydevd.py:2106\u001b[0m, in \u001b[0;36mPyDB._do_wait_suspend\u001b[0;34m(self, thread, frame, event, arg, suspend_type, from_this_thread, frames_tracker)\u001b[0m\n\u001b[1;32m   2103\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_input_hook()\n\u001b[1;32m   2105\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocess_internal_commands()\n\u001b[0;32m-> 2106\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2108\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcancel_async_evaluation(get_current_thread_id(thread), \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mid\u001b[39m(frame)))\n\u001b[1;32m   2110\u001b[0m \u001b[38;5;66;03m# process any stepping instructions\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "np.random.seed(1001)\n",
    "torch.manual_seed(0)\n",
    "\n",
    "x = np.random.rand(100, 5)\n",
    "torch_in = torch.from_numpy(x.astype(np.float32))\n",
    "\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    y = model.forward(torch_in).detach().numpy()\n",
    "\n",
    "with h5py.File('../models/2x16_test.h5', 'w') as file:\n",
    "    file.create_dataset('x', data=x)\n",
    "    file.create_dataset('y', data=y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wdf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
